{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "offensive-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !pip3 install tensorflow\n",
    "# !pip3 install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "simple-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from image_sparse_warp import *\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "demanding-pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-26 12:24:09.770141: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'\".\n",
      "2021-03-26 12:24:13.368280: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-26 12:24:13.381302: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbc326eecb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-26 12:24:13.381319: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "Traceback (most recent call last):\n",
      "  File \"ScanConvertTests.py\", line 53, in <module>\n",
      "    res = scan_convert_raw(ele['dtce'], empty_res_image, ele, points_xy, val_rtheta, val_weights)\n",
      "NameError: name 'scan_convert_raw' is not defined\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 ScanConvertTests.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weighted-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset \n",
    "ds = tfds.load('duke_ultrasound', data_dir='gs://tfds-data/datasets')\n",
    "test_dataset = ds['MARK'].map(process) # Splits: MARK, TRAIN, VALIDATION, TEST, A, B\n",
    "test_iter = iter(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gothic-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose next data point\n",
    "ele = next(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tough-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute step\n",
    "empty_res_image, points_xy, val_rtheta, val_weights = scan_convert_precompute(ele['dtce'], ele, ele['dtce'].shape[0], ele['dtce'].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decreased-specialist",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scan_convert_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6d0ee91d6feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Dynamic step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_convert_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtce'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mempty_res_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mele\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_xy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_rtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scan_convert_raw' is not defined"
     ]
    }
   ],
   "source": [
    "# Dynamic step\n",
    "t1 = time.perf_counter()\n",
    "res = scan_convert_raw(ele['dtce'], empty_res_image, ele, points_xy, val_rtheta, val_weights)\n",
    "t2 = time.perf_counter() - t1\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-germany",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = time.perf_counter()\n",
    "res_old = scan_convert_with_image_sparse_warp(ele['dtce'], ele, 17, 5)\n",
    "t4 = time.perf_counter() - t3\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(res_old)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
